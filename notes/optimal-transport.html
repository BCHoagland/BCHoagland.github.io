<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,700|Source+Sans+Pro:300,700" rel="stylesheet">
    <link rel="stylesheet" href="../styling/style.css">
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <title>Optimal Transport</title>
</head>
<body>

<div class="row">
    <div class="col-md-8">
        <div class="header">Optimal Transport</div>

        <p>
        The theory of optimal transport is an attempt by mathematicians to determine the optimal way in which to transform one probability
        distribution into another. Moreso than that, though, it gives us a more natural geometry for probability measures. We're used to picturing
        numbers on a grid and even distributions over part of a grid, but optimal transport gives us a way to visualize distributions of distributions.
        </p>

        <p>
        If we have two distributions, how similar are they? Can we define a distance between them? In the space of all possible distributions,
        where do they lie? These are the questions optimal transport seeks to answer.
        </p>

        <p>
        The optimal transport problem was first formulated by the French mathematician Monge as follows: given distributions \( \mu(x) \) and
        \( \nu(x) \), what is the optimal transport map \( T(x) \) such that \( \mu \) is mapped to \( \nu \)?
        </p>

        <p>
        An intuitive first step may be to say: "I don't want to move any probability mass a long distance, and moving a lot of mass would also be pretty
        difficult, so I want to minimize how much I move and how far I move it." Following this intuition, we can set up a expression to minimize:
        \[
        \mu(x) D(x, T(x))
        \]
        where \(D\) is some distance metric. This expression can be interpreted as follows: (how much you move) * (how far you move it).
        </p>

        <p>
        So far we have two constraints: we want to miminize the above expression, and we have to find a \(T\) that maps \(\mu\) entirely to \(\nu\).
        More generally, we can use a cost function \(c\) instead of a distance function \(D\). This gives us more flexibility over how difficult it
        is to actually move mass. These two constraints are the only things considered in the Monge formulation of the problem, which can be stated
        a bit more formally as:
        \[
        \inf_{T_{\#}\mu = \nu} \int c(x, T(x)) \; \mu(dx)
        \]
        where the notation \( T_\# \mu \) simply means that the function \( T \) maps \( \mu \) to \( \nu \). This is more formally called a
        "push-forward" and there are more subtle details associated with them, but for a general overview of optimal transport, delving into the minutiae
        isn't necessary.
        </p>

        <p>
        If you've seen anything related to optimal transport, you've probably seen formulas that look pretty different than this, and that's because
        the Monge formulation of the problem isn't the best. The biggest issue is that you can't split mass under this problem statement. Once again, I
        don't think diving into the subtle problems this causes is quite worth it for an introductory article, but trust me when I say that there are
        certain cases when no map \(T\) exists between \( \mu \) and \( \nu \).
        </p>

        <p>
        The Russian mathematician Kantorovich came along quite a while later and proposed another formulation of the problem that's more robust because it
        allows for mass-splitting. Instead of finding a map, Kantorovich instead proposed finding a <i>probabilistic</i> map ("coupling") that transforms
        \( \mu \) into \( \nu \).
        </p>

        <p>
        Imagine the set of all joint distributions of \( \mu \) and \( \nu \), which we can denote \( \Pi(\mu, \nu) \). We can search through this set
        to find the best joint distribution/coupling, stated more formally as:
        \[
        \inf_{P \in \Pi(\mu, \nu)} \int \int c(x, y) \; P(dx, dy)
        \]
        or equivalently:
        \[
        \inf_{P \in \Pi(\mu, \nu)} \mathbb{E}_{(x,y) \sim P} \big[ c(x, y) \big]
        \]
        So how do we solve this? Good question cause I have no idea. This is pretty messy, after all. Luckily for us, though, Kantorovich also found a nicer
        dual formulation of this expression that's easier to work with. One derivation is as follows:
        </p>

        <div class="subheader">Kantorovich Dual Formulation - Derivation</div>

        <p>
        Notice that the primal form of the problem, stated above, is a constrained optimization problem, and those are hard to solve.
        It would be nice if we could make it unconstrained, and we can do this by finding
        an unconstrained problem with the same solution and solving that instead. Let's introduce the regularizer \(\iota_{\Pi}(P)\), which takes
        in a coupling and outputs a real number according to
        \[
        \sup_{\varphi, \psi} \Bigg[ \int\varphi \;d\mu + \int\psi \;d\nu - \int\int\varphi \oplus \psi \;dP \Bigg]
        \]
        Let's unravel this and see why it'll be useful. First, the expression \((f \oplus g)(x,y)\) means \(f(x) + g(y)\). I used it only because it
        makes the double integral a bit easier to write. Second, let's think about what this function outputs for different couplings \(P\). If
        \(P \in \Pi(\mu, \nu)\), then the double integral becomes the same thing as the two single integrals on its left. They then cancel out and leave us
        with an output of 0. On the other hand, if \(P \notin \Pi(\mu, \nu)\), then nothing necessarily cancels out. In fact, we can find \(\varphi\) and \(\psi\)
        which output arbitrarily high values to parts of \(\mu\) and \(\nu\) that \(P\) more or less ignores, resulting in our regularizer outputting
        \(+ \infty\). Thus we have
        \[
        \iota_{\Pi}(P) =
        \begin{cases}
        0 & \text{if } P \in \Pi(\mu, \nu) \\
        +\infty & \text{if } P \notin \Pi(\mu, \nu)
        \end{cases}
        \]
        When we write it like this, it's more obvious that our regularizer is basically saying: "If \(P\) isn't a coupling for \(\mu\) and \(\nu\), add
        an infinitely large penalty." If we've added an infintely large penalty to something, it definitely isn't going to be the infimum, so now we can
        add this to our original expression and get rid of the constrained part. Our new expression is
        \[
        \inf_{P} \int \int c \;dP + \iota_{\Pi}(P)
        \]
        and in expanded form
        \[
        \inf_{P} \int \int c \;dP + \sup_{\varphi, \psi} \Bigg[ \int\varphi \;d\mu + \int\psi \;d\nu - \int\int\varphi \oplus \psi \;dP \Bigg]
        \]
        </p>

        <p>
        Since the first integral doesn't rely on \(\varphi\) or \(\psi\), we can pull the supremum out
        \[
        \inf_{P} \sup_{\varphi, \psi} \int \int c \;dP + \int\varphi \;d\mu + \int\psi \;d\nu - \int\int\varphi \oplus \psi \;dP
        \]
        </p>

        <p>
        Combining the two integrals over \(P\) yields
        \[
        \inf_{P} \sup_{\varphi, \psi} \int \int (c - \varphi \oplus \psi) \;dP + \int\varphi \;d\mu + \int\psi \;d\nu
        \]
        </p>

        <p>
        Since \( \sup_y \inf_x f(x,y) \leq \inf_x \sup_y f(x,y) \), we can swap the infimum and supremum while still having an answer with minimal value
        \[
        \sup_{\varphi, \psi} \color{blue}{ \inf_{P} \int \int (c - \varphi \oplus \psi) \;dP} + \int\varphi \;d\mu + \int\psi \;d\nu
        \]
        </p>

        <p>
        I also took the liberty in that step of coloring one integral blue. As it turns out, we can really simplify this part of the expression.
        First note that the two integrals on the far right of the expression don't affect the infimum at all since neither relies on \(P\), so we can just
        focus on the blue terms.
        </p>

        <p>
        If \( c - \varphi \oplus \psi \geq 0 \) at all points, then the infimum is clearly 0 (this means that \(c - \varphi \oplus \psi = 0\) at all points).
        If \(c - \varphi \oplus \psi < 0\) at <i>any</i> point, we can find a \(P\) that puts infinite mass on that negative point and make the whole
        integral \(-\infty\). For the sake of the simplicity of the expression, we'll add the constraint \( c - \varphi \oplus \psi \geq 0 \) and
        consequently replace the blue integral with the number 0.
        \[
        \sup_{c - \varphi \oplus \psi \geq 0} 0 + \int\varphi \;d\mu + \int\psi \;d\nu
        \]
        And we can clean up the notation just a bit further to get
        \[
        \sup_{\varphi \oplus \psi \leq c} \int\varphi \;d\mu + \int\psi \;d\nu
        \]
        That's it, really. This already seems easier to evaluate (we're not searching through a space of joint distributions anymore, just normal
        functions), but we can make this even easier to use if we use a specific cost function that we know how to analyze.
        </p>

        <div class="subheader">Wasserstein Distance</div>

        <p>
        If we use a distance measure as our cost function, then we define what's called the Wasserstein distance.
        Just as a \(p\)-norm over a function \(f\) is defined \( \big( \int |f(x)|^p \;dx \big)^{1/p} \), we can form a similar definition
        of the Wasserstein-p distance
        \[
        W_p(\mu, \nu) \doteq \Big( \inf_{P \in \Pi(\mu, \nu)} \int\int D^p \;dP \Big)^{1/p}
        \]
        where \(D(x,y)\) is the distance between points \(x\) and \(y\). Because roots are annoying to deal with, it's common to work with
        \(W_p^p\) (the subscript is just a subscript, the superscript is an exponent. Convention's weird like that...) instead of \(W_p\).
        Note that we can easily put this into its dual form, too
        \[
        W_p^p(\mu, \nu) = \sup_{\varphi \oplus \psi \leq D^p} \int\varphi \;d\mu + \int\psi \;d\nu
        \]
        </p>

        <p>
        Given a \(\varphi\), the best \(\psi\) we can get is
        \[
        \psi(y) = \bar{\varphi}(y) \doteq \inf_x D(x,y)^p - \varphi(x)
        \]
        We can get to this conclusion by noting the constraint in the supremum: \(\varphi(x) + \psi(y) \leq D(x,y)^p\). If we then make \(\psi\) as
        small as possible across all points (could even be negative for lots of points), then we end up making \(\varphi\) as large as possible across
        all points. This gives us the semi-dual form
        \[
        W_p^p(\mu, \nu) = \sup_{\varphi} \int\varphi \;d\mu + \int\bar{\varphi} \;d\nu
        \]
        </p>

        <p>
        One last simplification can be made if we set \(p=1\). In this case, I'm just gonna state without any kind of proof that if \(\varphi\)
        is a 1-Lipschitz function, then \( \bar{\varphi} = -\varphi \). This gives us the expression found in the Wasserstein GAN paper
        \[
        W_1^1(\mu, \nu) = W_1(\mu, \nu) = \sup_{\varphi \text{ is 1-Lipschitz}} \int\varphi \;d\mu - \int\varphi \;d\nu
        \]
        which can be expressed more familiarly as
        \[
        W_1(\mu, \nu) = \sup_{\varphi \text{ is 1-Lipschitz}} \mathbb{E}_{x \sim \mu} \big[ \varphi(x) \big] - \mathbb{E}_{y \sim \nu} \big[ \varphi(y) \big]
        \]
        </p>

        <div class="subheader">An Application!</div>

        <p>
        If you're wondering how this helps, you aren't alone. When I was first introduced to optimal transport, I wondered how much this
        <i>actually</i> helps. After all, our final expressions are still pretty complicated. If I wanted to transform one distribution into
        another, why not just use something much simpler like expectation maximization?
        </p>

        <p>
        The simple answer: this actually works better! Expectation maximization requires knowing exactly how to calculate log probabilities of your
        model distribution. This is really easy to do if you use a simple model, like a Gaussian, but what if your target distribution is really wack?
        Energy-based models seem like a great alternative since they're so versatile, but it's real intractable to calculate log probabilities for them.
        Since our optimal transport objectives don't rely on probability explicitly, though, we could use them to optimize an energy-based model, though.
        </p>

        <p>
        I was actually curious to see if other people had had this same idea, so I did some research mid-article-writing and found that OpenAI beat me
        to the punch. They use a modified Wasserstein GAN objective to create an energy-based model for image generation. If you're interested
        in the paper, you can find it <a href="https://arxiv.org/pdf/1903.08689.pdf">here</a>.
        </p>

        <div class="subheader">Quick Tangent about Differentiability</div>

        <p>
        In the machine learning world, if a function isn't differentiable, it's as good as useless. As it turns out, the Wasserstein distance
        by itself isn't differentiable. In fact, it's pretty unstable and the answers to two seemingly similar problems could be pretty different.
        But people use this in machine learning algorithms, so what's going on?
        </p>

        <p>
        From a programming perspective, we're only approximating the true Wasserstein distance, and we're doing this with networks defined by
        simple tensor operations (which we can use auto-differentiation software with). In a more mathematical sense, this approximation can
        be thought of as finding a modified Wasserstein distance that has an entropy term. If this entropy term is nonzero, the distance expression
        has a unique solution and it can be expressed as the result of some basic tensor operations because some mathematicians proved it could.
        This is clearly differentiable, and moreover, it's the basis of the popular Sinkhorn-Knopp algorithm for calculating the Wasserstein
        distance without using anything related to neural networks.
        </p>
    </div>
</div>

</body>
</html>