<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,700|Source+Sans+Pro:300,700" rel="stylesheet">
    <link rel="stylesheet" href="../styling/style.css">
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <title>Max Entropy RL</title>
</head>
<body>

<div id="home-link"><a href="/">Home</a></div>

<div class="row">
    <div class="col-md-8">
        <div class="header">Maximum Entropy Reinforcement Learning</div>

        <p>
        I'm gonna need some motivation to write this cause I'm exhausted. I wrote out the algorithm, though, so that's something.
        </p>

        <div class="algo">
        <div>Soft Actor-Critic (SAC)</div>
        Initialize \(\theta_1\), \(\theta_2\), and \(\phi\) <br/>
        \( \bar{\theta}_1 \gets \theta_1, \bar{\theta}_2 \gets \theta_2 \) <br/>
        Initialize replay buffer \(\mathcal{D}\) <br/><br/>

        Repeat: <br/>
            <div>
            For each environment step: <br/>
                <div>
                \( a \sim \pi_\phi \) <br/>
                Observe \( s', r \) <br/>
                Store (\(s,a,r,s'\)) in \(\mathcal{D}\) <br/><br/>
                </div>
            For \(K\) epochs: <br/>
                <div>
                \( \theta_i \gets \theta_i - \lambda_Q \hat{\nabla}_{\theta_i} J_Q(\theta_i) \), for \(i \in {1, 2} \) <br/>
                \( \phi \gets \phi - \lambda_\pi \hat{\nabla}_{\phi} J_\pi(\phi) \) <br/>
                \( \alpha \gets \alpha - \lambda \hat{\nabla}_{\alpha} J(\alpha) \) <br/><br/>

                \( \bar{\theta}_i \gets \tau\bar{\theta}_i + (1 - \tau)\theta_i \)
                </div>
            </div>
        </div>
    </div>
</div>

</body>
</html>
