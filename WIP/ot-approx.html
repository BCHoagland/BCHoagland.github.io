<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,700|Source+Sans+Pro:300,700" rel="stylesheet">
    <link rel="stylesheet" href="../styling/style.css">
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    <title>Optimal Transport Approximations</title>
</head>
<body>

<div class="row">
    <div class="col-md-8">
        <div class="header">Optimal Transport Approximations</div>

        <p>
        It's pretty natural to ask how Wasserstein distances can be approximated in applications, as even the simplest expressions for such distances
        tend to be a bit complicated. We can start with the Wasserstein-1 approximation that the WGAN paper uses, as it's pretty straightforward.
        </p>

        <div class="subheader">Lipschitz Strategy</div>
        <p>
        <span style="color:red">WGAN stuff</span>
        </p>

        <div class="subheader">Convexity Strategy</div>

        <p>
        This works pretty well, especially with the gradient penalty instead of the clipped weights. Other papers have come out on the topic, too,
        proposing simpler regularizers that seem to be more stable. An inherent problem in this approach, though, is continuity of the final network.
        Neural networks inherently approximate continuous functions just because of how tensor operations tend to work. If you put in similar input, your
        network will give you similar output. This is something that we actually rely on in topics like reinforcement learning, but it's not desirable
        when we want to model a given distribution perfectly. If our target distribution has zero density over a particular area, neither should our
        trained
        network. In practice, though, this is hard to avoid.
        </p>

        <p>
        One attempt at a solution that seems to work pretty well is to train our networks adversarially (just as before), but with a slight catch:
        neither
        one of them is actually the optimal transfer map. The map is actually the gradient of one of the networks. I won't pretend like this is
        intuitive,
        but it's a well established fact that if an optimal transport map exists, then it's the gradient of <i>some</i> convex function. We just
        need to
        train
        a network to be this convex function, and then it's just some gradient calculations until we have our map.
        </p>

        <p>
        So why is this better at all? This is really just taking neural networks and exploiting the nonlinearity of their activation functions. If the
        target
        distribution we want to model has discontinuous support, then it makes sense to model it with something that allows for discontinuities. If we
        think
        of the common ReLU activation function, it's pretty clear that its gradient is discontinuous even though its output isn't. This naturally
        discontinuous model will suit us pretty well.
        </p>

        <p>
        Another tool we'll need is neural networks that obey the laws of convexity. We know how to make these (and it's actually pretty simple), so we
        can
        black box them. I'll refer to them as ICNNs (input convex neural networks) from now on, and \( \text{ICNN}(\mathbb{R}^d) \) refers to a
        network that represents a convex function \( \mathbb{R}^d \to \mathbb{R} \).
        </p>

        <p>
        As a final point before diving in, it's important to think about what the set of all convex functions looks like in comparison to the set of
        all
        Lipschitz functions. It's going to be less restrictive (we won't use any regularizers to derive it),
        and thus easier to navigate through gradient steps. Thus we can expect that we'll find
        <i>the</i> optimal transport map, not just a local optimum, more easily with this method than with WGANs.
        </p>

        <div class="subheader">Convexity Strategy: Algorithm Derivation</div>

        <p>
        We'll begin the derivation with the Kantorovich dual form of the Wasserstein-2 distance between two distributions \(P\) and \(Q\)
        \[
        W_2^2(P,Q) = \sup_{(f,g) \in \Phi} \mathbb{E}_P[f(X)] + \mathbb{E}_Q[g(Y)]
        \]
        where \(\Phi\) represents the set of function pairs which satisfy \( f(x) + g(y) \leq \frac{1}{2} \Vert x-y \Vert^2 \).
        Assuming our distributions are over the real numbers, we can do some rearranging of terms and substituting and
        derive the following relationship
        \[
        \begin{align*}
        f(x) + g(y) &\leq \frac{1}{2} \Vert x-y \Vert^2 \\
        2f(x) + 2g(y) &\leq \Vert x \Vert^2 -2 \langle x, y \rangle + \Vert y \Vert^2 \\
        \Big[ \frac{1}{2} \Vert x \Vert^2 - f(x) \Big] + \Big[ \frac{1}{2} \Vert y \Vert^2 - g(y) \Big] &\geq \langle x, y \rangle
        \end{align*}
        \]
        Now instead of searching through \(\Phi\) for our \(f\) and \(g\), we'll search for the reparameterized
        \(f(x) = \frac{1}{2} \Vert x \Vert^2 - f(x) \) and
        \(g(y) = \frac{1}{2} \Vert y \Vert^2 - g(y) \) in the set \(\tilde{\Phi}\), whose elements (once again function pairs) satisfy the constraint
        \( f(x) + g(y) \geq \langle x,y \rangle \). Substituting these new \(f\) and \(g\) definitions into our Wasserstein-2 definition yields
        \[
        \begin{align*}
        W_2^2(P,Q) &= \sup_{(f,g) \in \Phi} \mathbb{E}_P[f(X)] + \mathbb{E}_Q[g(Y)] \\
        &= \sup_{(f,g) \in \color{blue}{\tilde{\Phi}}} \mathbb{E}_P \Big[ \frac{1}{2} \Vert X \Vert^2 - f(X) \Big] +
        \mathbb{E}_Q \Big[ \frac{1}{2} \Vert Y \Vert^2 - g(Y) \Big] \\
        &= \frac{1}{2} \mathbb{E}_P \Big[ \Vert X \Vert^2 \Big] + \frac{1}{2} \mathbb{E}_Q \Big[ \Vert Y \Vert^2 \Big] +
        \sup_{(f,g) \in \tilde{\Phi}} \Big\{ - \mathbb{E}_P \big[f(X)\big] - \mathbb{E}_Q \big[g(Y)\big] \Big\} \\
        &= \frac{1}{2} \mathbb{E}_P \Big[ \Vert X \Vert^2 \Big] + \frac{1}{2} \mathbb{E}_Q \Big[ \Vert Y \Vert^2 \Big] -
        \inf_{(f,g) \in \tilde{\Phi}} \Big\{ \mathbb{E}_P \big[f(X)\big] + \mathbb{E}_Q \big[g(Y)\big] \Big\}
        \end{align*}
        \]
        </p>

        <p>
        We can put this in terms of one variable in a manner similar to how we did so when deriving the original Kantorovich dual form for Lipschitz
        functions. The only difference is that this time, we also need to add a convexity requirement to our function \(f\)
        \[
        \inf_{(f,g) \in \tilde{\Phi}} \Big\{ \mathbb{E}_P \big[f(X)\big] + \mathbb{E}_Q \big[g(Y)\big] \Big\} =
        \inf_{f \text{ is convex in } \mathbb{R}^d} \mathbb{E}_P \big[f(X)\big] + \mathbb{E}_Q \big[f^*(Y)\big]
        \]
        where the function \(f^*(y) = \sup_x \langle x,y \rangle - f(x)\) is the convex conjugate of \(f\).
        </p>

        <p>
        Based on Brenier's Theorem, we know that if \(Q\) admits a density on \(\mathbb{R}^d\) then a unique optimal transport map exists and is known
        to be \(\nabla f^*\). Assuming that \(Q\) admits a density, the rest of the derivation falls into place. First note that the terms
        \( \frac{1}{2} \mathbb{E}_P \Big[ \Vert X \Vert^2 \Big] + \frac{1}{2} \mathbb{E}_Q \Big[ \Vert Y \Vert^2 \Big] \)
        in our definition of the Wasserstein-2 distance don't rely on \(f\) or \(g\), so we can omit them when performing our optimization.
        Substituting in the convex conjugate and getting rid of the constant terms leaves us with the objective
        \[
        \begin{align*}
            J(P,Q) &= - \inf_{f \text{ convex}} \sup_{g \text{ convex}} \mathbb{E}_P \big[f(X)\big]
            + \mathbb{E}_Q \big[\langle \nabla g(Y),Y \rangle - f(\nabla g(Y)) \big] \\
            &= \sup_{f \text{ convex}} \inf_{g \text{ convex}} \mathbb{E}_P \big[- f(X)\big]
            + \mathbb{E}_Q \big[- \langle \nabla g(Y),Y \rangle + f(\nabla g(Y)) \big]
        \end{align*}
        \]
        Note that in the above steps, I replace \(f*\) with \(g\). It plays the same role but makes the notation clearer.
        </p>
        
        <p>
        We can approximate this objective by using ICNNs
        \[
        \tilde{J}(P,Q) = \sup_{f\in\text{ICNN}(\mathbb{R}^d)} \inf_{f\in\text{ICNN}(\mathbb{R}^d)} \mathbb{E}_P \big[- f(X)\big]
        + \mathbb{E}_Q \big[- \langle \nabla g(Y),Y \rangle + f(\nabla g(Y)) \big]
        \]
        In practice we approximate this further with sampling, but it's also been shown empirically that we can lighten the convexity restraint
        on \(g\), instead using a soft penalty.
        \[
        \hat{J}(P, Q) = \max_{\theta_f; f_\theta \text{ is ICNN}} \min_{\theta_g} \frac{1}{N} \sum_{i=1}^N f(\nabla g(Y_i)) - f(X_i)
        - \langle \nabla g(Y_i),Y_i \rangle + R(\theta_g)
        \]
        where \(R(\theta_g)\) is a quadratic penalty on certain weights in \(\theta_g\) that must be non-negative in order for the network to be convex
        over its input. This is all we need to form an algorithm for convexity-based Wasserstein-2 approximation
        </p>

        <div class="algo">
        <div>Wasserstein-2 Approximation with ICNNs</div>
        Repeat:
            <div>
            Sample \( \{X_i\}_{i=1}^N \sim P\) <br/>
            For K steps:
            <div>
                Sample \( \{Y_i\}_{i=1}^N \sim Q\) <br/>
                Update \(\theta_g\) using Adam to minimize \(\hat{J}\)
            </div>
            Update \(\theta_f\) using Adam to maximize \(\hat{J}\) <br/>
            \( w \gets \max(w,0) \) for all \( w \in \theta_f \) that must be non-negative to ensure convexity
            </div>
        </div>
    </div>
</div>

</body>
</html>